{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests KNN\n",
    "\n",
    "This notebook is quite useless for the `siamese` itself but it was my testing notebook for the `K-NN` optimization. Therefore I think it can berelevant to leave it if you want to further improve it or make tests ot add new features\n",
    "\n",
    "The `KNN` is my old numpy implementation while `TFKNN` is the one used in `distance/knn.py` which is optimized in pure `tensorflow` with `knn` core decision rule as `tf.function` decorated\n",
    "\n",
    "Also I find it quite impressive to see that the tensorflow version is 10 times faster than the `numpy` implementation !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.plot_utils import plot_embedding\n",
    "from utils.thread_utils import ThreadPool\n",
    "from utils.embeddings import load_embedding, embeddings_to_np\n",
    "from utils.distance.distance_method import distance\n",
    "\n",
    "class KNN(object):\n",
    "    def __init__(self, embeddings, ids = None, k = 5, use_mean = False, \n",
    "                 method = 'euclidian', ** kwargs):\n",
    "        if isinstance(embeddings, str):\n",
    "            embeddings = load_embedding(embeddings)\n",
    "        \n",
    "        if isinstance(embeddings, pd.DataFrame):\n",
    "            ids = embeddings['id'].values\n",
    "            embeddings = embeddings_to_np(embeddings)\n",
    "        \n",
    "        self.ids    = np.array(ids)\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self.k          = k if not use_mean else 1\n",
    "        self.method     = method\n",
    "        self.use_mean   = use_mean\n",
    "        \n",
    "        self.mean_ids, self.mean_embeddings = self.get_mean_embeddings()\n",
    "\n",
    "    def get_mean_embeddings(self, embeddings = None, ids = None):\n",
    "        if embeddings is None:\n",
    "            embeddings, ids = self.embeddings, self.ids\n",
    "        \n",
    "        uniques = np.unique(ids)\n",
    "        return uniques, np.array([\n",
    "            np.mean(embeddings[self.ids == unique_id], axis = 0)\n",
    "            for unique_id in uniques\n",
    "        ])\n",
    "    \n",
    "    def get_embeddings(self, ids = None, use_mean = False):\n",
    "        if ids is not None and not isinstance(ids, (list, tuple, np.ndarray)): ids = [ids]\n",
    "        if use_mean:\n",
    "            res_embeddings, res_ids = self.mean_embeddings, self.mean_ids\n",
    "        else:\n",
    "            res_embeddings, res_ids = self.embeddings, self.ids\n",
    "        \n",
    "        if ids is not None:\n",
    "            indexes = np.array([\n",
    "                id_i in ids for id_i in res_ids\n",
    "            ])\n",
    "            res_embeddings = res_embeddings[indexes]\n",
    "            res_ids = res_ids[indexes]\n",
    "        \n",
    "        return res_embeddings, res_ids\n",
    "    \n",
    "    def distance(self, x, ids = None, use_mean = False):\n",
    "        embeddings, ids = self.get_embeddings(ids, use_mean)\n",
    "        return distance(x, embeddings, method = self.method), ids\n",
    "        \n",
    "    def predict(self, x, possible_ids = None, k = None, use_mean = None, plot = False, ** kwargs):\n",
    "        if isinstance(x, tf.Tensor): x = x.numpy()\n",
    "        assert isinstance(x, np.ndarray) and x.ndim in (1, 2)\n",
    "\n",
    "        if use_mean is None: use_mean = self.use_mean\n",
    "        if use_mean: k = 1\n",
    "        elif not k: k = self.k\n",
    "        \n",
    "        if possible_ids is not None:\n",
    "            if not isinstance(possible_ids, (list, tuple, np.ndarray)): \n",
    "                possible_ids = [possible_ids]\n",
    "            \n",
    "        \n",
    "        if x.ndim == 2:\n",
    "            if possible_ids is None: possible_ids = [None] * len(x)\n",
    "            elif len(possible_ids) != len(x):\n",
    "                possible_ids = [possible_ids] * len(x)\n",
    "\n",
    "            assert len(possible_ids) == len(x)\n",
    "            \n",
    "            pool = ThreadPool(target = self.predict)\n",
    "            for xi, ids_i in zip(x, possible_ids):\n",
    "                pool.append(kwargs = {\n",
    "                    'x' : xi, 'possible_ids' : ids_i, 'plot' : False,\n",
    "                    'k' : k, 'use_mean' : use_mean, ** kwargs\n",
    "                })\n",
    "            pool.start(tqdm = lambda x: x)\n",
    "            \n",
    "            pred = np.array(pool.result())\n",
    "            #pred = np.array([\n",
    "            #    self.predict(xi, ids_i, k = k, use_mean = use_mean, plot = False, ** kwargs) \n",
    "            #    for xi, ids_i in zip(x, possible_ids)\n",
    "            #])\n",
    "        else:\n",
    "            if possible_ids is not None and len(possible_ids) == 0: return -1\n",
    "            \n",
    "            distance, ids = self.distance(x, ids = possible_ids, use_mean = use_mean)\n",
    "\n",
    "            k_nearest_idx = np.argsort(distance)[:k]\n",
    "\n",
    "            nearest_ids = {}\n",
    "            for nearest_id in ids[k_nearest_idx]:\n",
    "                nearest_ids.setdefault(nearest_id, 0)\n",
    "                nearest_ids[nearest_id] += 1\n",
    "\n",
    "            best_id, n = [], 0\n",
    "            for nearest_id, n_times in nearest_ids.items():\n",
    "                if n_times > n: best_id, n = [nearest_id], n_times\n",
    "                elif n_times == n: best_id.append(nearest_id)\n",
    "\n",
    "            pred = best_id[0] if len(best_id) == 1 else -2\n",
    "        \n",
    "        if plot:\n",
    "            self.plot(x, pred, ** kwargs)\n",
    "            \n",
    "        return pred\n",
    "    \n",
    "    def plot(self, x = None, x_ids = None, marker_kwargs = None, ** kwargs):\n",
    "        if marker_kwargs is None: marker_kwargs = {}\n",
    "\n",
    "        # Original points\n",
    "        embeddings, ids = self.embeddings, self.ids\n",
    "        marker = ['o'] * len(embeddings)\n",
    "        \n",
    "        # Means as big points\n",
    "        embeddings = np.concatenate([embeddings, self.mean_embeddings], axis = 0)\n",
    "        ids = np.concatenate([ids, self.mean_ids], axis = 0)\n",
    "        \n",
    "        marker += ['O'] * len(self.mean_ids)\n",
    "        marker_kwargs.setdefault('O', {\n",
    "            'marker'    : 'o',\n",
    "            'linewidth' : kwargs.get('linewidth', 2.5) * 3\n",
    "        })\n",
    "        \n",
    "        # New data points to plot\n",
    "        if x is not None:\n",
    "            if isinstance(x, pd.DataFrame):\n",
    "                if 'id' in x and x_ids is None:\n",
    "                    x_ids = x['id'].values\n",
    "                x = embeddings_to_np(x)\n",
    "            \n",
    "            if x.ndim == 1: x = np.expand_dims(x, 0)\n",
    "            if x_ids is not None:\n",
    "                if not isinstance(x_ids, (list, tuple, np.ndarray)): x_ids = [x_ids]\n",
    "                x_ids = np.array(x_ids)\n",
    "            else:\n",
    "                fake_id = 0\n",
    "                while fake_id in ids: fake_id += 1\n",
    "                x_ids = np.array([fake_id] * len(x))\n",
    "                marker_kwargs.setdefault('x', {'c' : 'w'})\n",
    "            \n",
    "            assert len(x_ids) == len(x)\n",
    "            \n",
    "            embeddings = np.concatenate([embeddings, x], axis = 0)\n",
    "            ids = np.concatenate([ids, x_ids], axis = 0)\n",
    "            marker += ['x'] * len(x)\n",
    "        \n",
    "        plot_embedding(\n",
    "            embeddings, ids = ids, marker = np.array(marker), \n",
    "            marker_kwargs = marker_kwargs, ** kwargs\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.thread_utils import ThreadPool\n",
    "from utils.plot_utils import plot_embedding\n",
    "from utils.embeddings import load_embedding, compute_mean_embeddings, embeddings_to_np\n",
    "from utils.distance.distance_method import distance\n",
    "\n",
    "class TFKNN(object):\n",
    "    \"\"\"\n",
    "        Tensorflow implementation of the `K-Nearest Neighbors` algorithm\n",
    "        \n",
    "        It also has some additional features such as : \n",
    "            - Plotting embeddings / predictions\n",
    "            - Use a `use_mean` version where the prediction is the nearest `centroid`*\n",
    "            \n",
    "        * A `centroid` is the mean point of all points belonging to a given label\n",
    "    \"\"\"\n",
    "    def __init__(self, embeddings, ids = None, k = 5, use_mean = False, \n",
    "                 method = 'euclidian', ** kwargs):\n",
    "        \"\"\"\n",
    "            Constructor for the KNN class\n",
    "            \n",
    "            Arguments : \n",
    "                - embeddings    : the embeddings to use as labelled points\n",
    "                    If str  : call `load_embedding()` on it\n",
    "                    If pd.DataFrame : use the 'id' column for `ids` and call `embeddings_to_np` on it\n",
    "                    Else    : must be a np.ndarray / tf.Tensor 2D matrix\n",
    "                - ids   : ids of the embeddings (if embeddings is a DataFrame, ids = embeddings['id'].values)\n",
    "                - k / use_mean  : default configuration for the `predict` method\n",
    "                - method        : distance method to use\n",
    "        \"\"\"\n",
    "        if isinstance(embeddings, str):\n",
    "            embeddings = load_embedding(embeddings)\n",
    "        \n",
    "        if isinstance(embeddings, pd.DataFrame):\n",
    "            ids = embeddings['id'].values\n",
    "            embeddings = embeddings_to_np(embeddings)\n",
    "        \n",
    "        assert len(embeddings) == len(ids)\n",
    "        \n",
    "        self.ids    = np.array(ids)\n",
    "        self.embeddings = tf.cast(embeddings, tf.float32)\n",
    "        \n",
    "        self.k          = tf.cast(k, dtype = tf.int32)\n",
    "        self.use_mean   = use_mean\n",
    "        self.method     = method\n",
    "        \n",
    "        self.mean_ids, self.mean_embeddings = self.get_mean_embeddings()\n",
    "    \n",
    "    def get_mean_embeddings(self):\n",
    "        \"\"\" Compute the mean embeddings for each id \"\"\"\n",
    "        return compute_mean_embeddings(self.embeddings, self.ids)\n",
    "    \n",
    "    def get_embeddings(self, ids = None, use_mean = False):\n",
    "        \"\"\" Return all embeddings from specified ids \"\"\"\n",
    "        if ids is not None and not isinstance(ids, (list, tuple, np.ndarray, tf.Tensor)): ids = [ids]\n",
    "        if use_mean:\n",
    "            embeddings, res_ids = self.mean_embeddings, self.mean_ids\n",
    "        else:\n",
    "            embeddings, res_ids = self.embeddings, self.ids\n",
    "        \n",
    "        if ids is not None:\n",
    "            indexes = tf.concat([\n",
    "                tf.where(res_ids == id_i) for id_i in ids\n",
    "            ], axis = 0)\n",
    "            embeddings = tf.gather(embeddings, indexes)\n",
    "            res_ids = tf.gather(res_ids, indexes)\n",
    "        \n",
    "        return embeddings, res_ids\n",
    "    \n",
    "    def distance(self, x, ids = None, use_mean = False):\n",
    "        \"\"\" Compute distance between x and embeddings for given ids \"\"\"\n",
    "        embeddings, ids = self.get_embeddings(ids, use_mean)\n",
    "        return distance(tf.cast(x, tf.float32), embeddings, method = self.method), ids\n",
    "    \n",
    "    def predict(self, x, possible_ids = None, k = None, use_mean = None,\n",
    "                plot = False, tqdm = lambda x: x, ** kwargs):\n",
    "        \"\"\"\n",
    "            Predict ids for each `x` vector based on the `k-nn` decision procedure\n",
    "            \n",
    "            Arguments :\n",
    "                - x : the 1D / 2D matrix of embeddings vector(s) to predict label\n",
    "                - possible_ids  : a list of `possible ids` (other ids are not taken into account for the k-nn)\n",
    "                - k / use_mean  : k-nn metaparameter (if not provided use self.k / self.use_mean)\n",
    "                - tqdm  : progress bar if `x` is a matrix\n",
    "                - plot / kwargs : whether to plot the prediction result or not\n",
    "            \n",
    "            If x is a matrix, call `self.predict` for each vector in the matrix in a multi-threaded way\n",
    "            It allows to achieve really good performances even for prediction on a large dataset\n",
    "        \"\"\"\n",
    "        if use_mean is None: use_mean = self.use_mean\n",
    "        if use_mean: k = 1\n",
    "        elif k is None: k = self.k\n",
    "        else: k = tf.cast(k, tf.int32)\n",
    "        \n",
    "        if possible_ids is not None and not isinstance(possible_ids, (list, tuple, np.ndarray)):\n",
    "            possible_ids = [possible_ids]\n",
    "        \n",
    "        x = tf.cast(x, tf.float32)\n",
    "        if tf.rank(x) == 2:\n",
    "            if possible_ids is None: possible_ids = [None] * len(x)\n",
    "            elif len(possible_ids) != len(x):\n",
    "                possible_ids = [possible_ids] * len(x)\n",
    "\n",
    "            assert len(possible_ids) == len(x)\n",
    "            \n",
    "            pool = ThreadPool(target = self.predict)\n",
    "            for xi, ids_i in zip(x, possible_ids):\n",
    "                pool.append(kwargs = {\n",
    "                    'x' : xi, 'possible_ids' : ids_i, 'k' : k, 'use_mean' : use_mean\n",
    "                })\n",
    "            pool.start(tqdm = tqdm)\n",
    "            \n",
    "            pred = tf.concat(pool.result(), axis = 0)\n",
    "        else:\n",
    "            embeddings, ids = self.get_embeddings(possible_ids, use_mean)\n",
    "            \n",
    "            pred = knn(x, embeddings, ids, k, self.method)\n",
    "        \n",
    "        if plot:\n",
    "            self.plot(x, pred, ** kwargs)\n",
    "        \n",
    "        return pred\n",
    "        \n",
    "    def plot(self, x = None, x_ids = None, marker_kwargs = None, ** kwargs):\n",
    "        \"\"\"\n",
    "            Plot the labelled datasets + centroids + possible `x` to predict (with their predicted labels) \n",
    "        \"\"\"\n",
    "        if marker_kwargs is None: marker_kwargs = {}\n",
    "\n",
    "        # Original points\n",
    "        embeddings, ids = self.embeddings, self.ids\n",
    "        marker = ['o'] * len(embeddings)\n",
    "        \n",
    "        # Means as big points\n",
    "        embeddings = np.concatenate([embeddings, self.mean_embeddings], axis = 0)\n",
    "        ids = np.concatenate([ids, self.mean_ids], axis = 0)\n",
    "        \n",
    "        marker += ['O'] * len(self.mean_ids)\n",
    "        marker_kwargs.setdefault('O', {\n",
    "            'marker'    : 'o',\n",
    "            'linewidth' : kwargs.get('linewidth', 2.5) * 3\n",
    "        })\n",
    "        \n",
    "        # New data points to plot\n",
    "        if x is not None:\n",
    "            if isinstance(x, pd.DataFrame):\n",
    "                if 'id' in x and x_ids is None:\n",
    "                    x_ids = x['id'].values\n",
    "                x = embeddings_to_np(x)\n",
    "            \n",
    "            if x.ndim == 1: x = np.expand_dims(x, 0)\n",
    "            if x_ids is not None:\n",
    "                if not isinstance(x_ids, (list, tuple, np.ndarray)): x_ids = [x_ids]\n",
    "                x_ids = np.array(x_ids)\n",
    "            else:\n",
    "                fake_id = 0\n",
    "                while fake_id in ids: fake_id += 1\n",
    "                x_ids = np.array([fake_id] * len(x))\n",
    "                marker_kwargs.setdefault('x', {'c' : 'w'})\n",
    "            \n",
    "            assert len(x_ids) == len(x)\n",
    "            \n",
    "            embeddings = np.concatenate([embeddings, x], axis = 0)\n",
    "            ids = np.concatenate([ids, x_ids], axis = 0)\n",
    "            marker += ['x'] * len(x)\n",
    "        \n",
    "        plot_embedding(\n",
    "            embeddings, ids = ids, marker = np.array(marker), \n",
    "            marker_kwargs = marker_kwargs, ** kwargs\n",
    "        )\n",
    "\n",
    "@tf.function(experimental_relax_shapes = True)\n",
    "def knn(x, embeddings, ids, k, distance_metric):\n",
    "    \"\"\"\n",
    "        Compute the k-nn decision procedure for a given x based on a list of labelled embeddings\n",
    "        \n",
    "        Return the majoritary id in the `k` nearest neigbors or `-2` if there is an equality\n",
    "    \"\"\"\n",
    "    distances = tf.squeeze(distance(x, embeddings, method = distance_metric))\n",
    "    \n",
    "    k_nearest_val, k_nearest_idx = tf.nn.top_k(-distances, k)\n",
    "    \n",
    "    nearest_ids = tf.cast(tf.gather(ids, k_nearest_idx), tf.int32)\n",
    "    counts = tf.math.bincount(nearest_ids)\n",
    "\n",
    "    nearest_ids = tf.squeeze(tf.where(counts == tf.reduce_max(counts)))\n",
    "\n",
    "    return tf.cast(nearest_ids, tf.int32) if tf.rank(nearest_ids) == 0 else -2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction takes 78.444 sec !\n",
      "Prediction takes 8.078 sec !\n",
      "[-2 -2 -2 -2 -2]\n",
      "tf.Tensor([-2 -2 -2 -2 -2], shape=(5,), dtype=int32)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def predict(knn, embeddings):\n",
    "    t0 = time.time()\n",
    "    #pred = knn.get_embeddings(list(range(7)))\n",
    "    pred = knn.predict(embeddings, possible_ids = list(range(7)))\n",
    "    end = time.time() - t0\n",
    "    print(\"Prediction takes {:.3f} sec !\".format(end))\n",
    "    return pred\n",
    "\n",
    "n = 25000\n",
    "\n",
    "embeddings = np.random.random(size = (n, 128))\n",
    "ids = np.random.randint(0, 10, size = (n,))\n",
    "\n",
    "val_embeddings = np.random.random(size = (2500, 128))\n",
    "\n",
    "\n",
    "np_knn = KNN(embeddings, ids)\n",
    "tf_knn = TFKNN(embeddings, ids)\n",
    "\n",
    "np_pred = predict(np_knn, val_embeddings)\n",
    "tf_pred = predict(tf_knn, val_embeddings)\n",
    "print(np_pred[:5])\n",
    "print(tf_pred[:5])\n",
    "print(np.all(np_pred == tf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
